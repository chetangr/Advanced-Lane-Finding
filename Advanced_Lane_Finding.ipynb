{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Import\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import pickle\n",
    "from scipy.signal import find_peaks_cwt\n",
    "import time\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Load Camera Calibration Pickle Data\n",
    "dist_data = pickle.load( open( \"dist_pickle.p\", \"rb\" ) )\n",
    "camera_mtx = dist_data[\"mtx\"]\n",
    "camera_dist = dist_data[\"dist\"]\n",
    "\n",
    "### Load Images\n",
    "images = glob.glob('test_images/*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Display Function\n",
    "def disp_img(original_image, augmented_image, new_cmap=None, aug_title = \"\"):\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "    ax1.imshow(original_image)\n",
    "    ax2.imshow(augmented_image, cmap=new_cmap)\n",
    "    ax1.set_title('Original Image', fontsize=30)\n",
    "    ax2.set_title('Augmented Image: ' + aug_title, fontsize=30)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Color Thresholding\n",
    "def threshold(image, thresh_val):\n",
    "    return cv2.threshold(image, thresh_val[0], thresh_val[1], cv2.THRESH_BINARY)\n",
    "\n",
    "def color_threshold(img):\n",
    "    \n",
    "    # Channel based thresholding\n",
    "    # HLS\n",
    "    undist_hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    undist_S = undist_hls[:,:,2]\n",
    "    thresh_S = (180, 255)\n",
    "\n",
    "    binary_hls_S = np.zeros_like(undist_S)\n",
    "    _, binary_hls_S = threshold(undist_S, thresh_S)\n",
    "    \n",
    "\n",
    "    # LUV\n",
    "    undist_luv = cv2.cvtColor(img, cv2.COLOR_RGB2LUV)\n",
    "    undist_L = undist_luv[:,:,0]\n",
    "    thresh_L = (225, 255)\n",
    "\n",
    "    binary_luv_L = np.zeros_like(undist_L)\n",
    "    _, binary_luv_L = threshold(undist_L, thresh_L)\n",
    "    \n",
    "\n",
    "    # LAB\n",
    "    undist_lab = cv2.cvtColor(img, cv2.COLOR_RGB2Lab)\n",
    "    undist_B = undist_lab[:,:,2]\n",
    "    thresh_B = (150, 255)\n",
    "    binary_lab_B = np.zeros_like(undist_B)\n",
    "    _, binary_lab_B = threshold(undist_B, thresh_B)\n",
    "    \n",
    "    \n",
    "    # Combined Color Thresholding\n",
    "    combined_color_binary = np.zeros_like(binary_lab_B)\n",
    "    \n",
    "    #combined_color_binary[(binary_hls_S == 255) | (binary_luv_L == 255) | (binary_lab_B == 255)] = 255\n",
    "    combined_color_binary[(binary_luv_L == 255) | (binary_lab_B == 255)] = 255\n",
    "    return combined_color_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Perspective Transform\n",
    "\n",
    "def undistort_img(image):\n",
    "    # Undistort test image\n",
    "    undist_image = cv2.undistort(image, camera_mtx, camera_dist, None, camera_mtx)\n",
    "\n",
    "    img_size = (undist_image.shape[1], undist_image.shape[0])\n",
    "    \n",
    "    # Lane line vertices\n",
    "    # Upper and low are based on visual locations, not grid locations\n",
    "    center_x = img_size[0]//2\n",
    "    upper_y = img_size[1]//1.5\n",
    "    low_y = img_size[1]\n",
    "    upper_left_x = center_x//1.33\n",
    "    upper_right_x = center_x//0.80\n",
    "    low_left_x = 0\n",
    "    low_right_x = 2*center_x\n",
    "    \n",
    "    # Calculate source points based on fractions of imade dimensions\n",
    "    src_corners = np.float32([[low_left_x, low_y], \n",
    "                              [upper_left_x, upper_y], \n",
    "                              [upper_right_x, upper_y],\n",
    "                              [low_right_x, low_y]])\n",
    "   \n",
    "    \n",
    "    # Calculate destination points based on entire image's dimensions.\n",
    "    dst_corners = np.float32([[0, img_size[1]],\n",
    "                              [0, 0],\n",
    "                              [img_size[0],0],\n",
    "                              [img_size[0], img_size[1]]])\n",
    "    \n",
    "    return undist_image, src_corners, dst_corners\n",
    "\n",
    "def perspective_transform(image):\n",
    "    # Calculate perspective transform\n",
    "    \n",
    "    undist_image, src_corners, dst_corners = undistort_img(image)    \n",
    "    \n",
    "    img_size = (undist_image.shape[1], undist_image.shape[0])\n",
    "    \n",
    "    M = cv2.getPerspectiveTransform(src_corners, dst_corners)\n",
    "\n",
    "    warped = cv2.warpPerspective(undist_image, M, img_size)\n",
    "    \n",
    "    M_inv = cv2.getPerspectiveTransform(dst_corners, src_corners)\n",
    "\n",
    "    # Draw points and lines to mark region for transform\n",
    "    for i in range(4):\n",
    "        cv2.circle(undist_image, (src_corners[i,0], src_corners[i,1]), 6, (255, 0, 0), 6)\n",
    "    for i in range(4):\n",
    "        cv2.line(undist_image, \n",
    "                 (src_corners[i-1,0], src_corners[i-1,1]), \n",
    "                 (src_corners[i,0], src_corners[i,1]),  \n",
    "                 (0,255,0), 2)\n",
    "    \n",
    "        \n",
    "    return warped, M_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Color Thresholding on Bird-Eye View\n",
    "\n",
    "def thresholded_img(image):\n",
    "    # Image thresholding\n",
    "    warped, M_inv = perspective_transform(image)\n",
    "    blurred_warped = cv2.GaussianBlur(warped,(5,5),0)\n",
    "\n",
    "    # Color Thresholding\n",
    "    combined_color_binary = color_threshold(blurred_warped)\n",
    "    \n",
    "    return combined_color_binary, M_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Lane Finding\n",
    "def lane_coords(image):\n",
    "    \n",
    "    # Define image height and window size\n",
    "    img_dim_y = image.shape[0]\n",
    "    img_dim_x = image.shape[1]\n",
    "    img_slices = 10\n",
    "    win_size = img_dim_y//img_slices\n",
    "    \n",
    "    # Histogram\n",
    "    indexes = []\n",
    "    hist_val = []\n",
    "    \n",
    "    for i in range(img_slices):\n",
    "        histogram = np.mean(image[(img_slices-i-1)*win_size:(img_slices-i)*win_size,:], axis=0)\n",
    "        \n",
    "        # Histogram search area\n",
    "        left_half_min = 0\n",
    "        left_half_max = img_dim_x//2.5\n",
    "        right_half = img_dim_x-(img_dim_x//2.2)\n",
    "        \n",
    "        # Histogram peaks\n",
    "        hist_peaksl = np.argmax(histogram[left_half_min:left_half_max])\n",
    "        hist_peaksr = np.argmax(histogram[right_half:])\n",
    "        \n",
    "        # Reduce noise\n",
    "        if histogram[hist_peaksl+left_half_min] > 0.01:\n",
    "            hist_peaksl = int(hist_peaksl+left_half_min)\n",
    "        else:\n",
    "            hist_peaksl = 0\n",
    "        \n",
    "        if histogram[hist_peaksr + right_half] > 0.01:\n",
    "            hist_peaksr = int(hist_peaksr + right_half)\n",
    "        else:\n",
    "            hist_peaksr = 0\n",
    "        \n",
    "        # Append indices\n",
    "        indexes.append([hist_peaksl, hist_peaksr])\n",
    "    \n",
    "    \n",
    "    left_lane_idx = []\n",
    "    right_lane_idx = []\n",
    "    \n",
    "    \n",
    "    for i in range(img_slices):\n",
    "        # Define window y positions\n",
    "        win_y1 = (img_slices-i)*win_size\n",
    "        win_y2 = (img_slices-i)*win_size - win_size        \n",
    "\n",
    "        # Draw boxes and get indices of thresholded lane points\n",
    "        # Left Lane\n",
    "        if (indexes[i][0] != 0):\n",
    "            # Define window x positions\n",
    "            win_x1l = indexes[i][0] - (win_size//2)\n",
    "            win_x2l = indexes[i][0] + (win_size//2)\n",
    "            \n",
    "            # Identify lane points where line was detected\n",
    "            left_lane_idx_local = np.argwhere(image[win_y2:win_y1, win_x1l:win_x2l] > 0)\n",
    "            # Append to list of lane indices and apply frame of reference transformation\n",
    "            left_lane_idx.append(left_lane_idx_local + [win_y2,win_x1l])\n",
    "\n",
    "        # Right lane\n",
    "        if(indexes[i][1] != 0):\n",
    "            # Define window x positions\n",
    "            win_x1r = indexes[i][1] - (win_size//2)\n",
    "            win_x2r = indexes[i][1] + (win_size//2)\n",
    "            \n",
    "            # Identify lane points where line was detected\n",
    "            right_lane_idx_local = np.argwhere(image[win_y2:win_y1, win_x1r:win_x2r] > 0)\n",
    "            \n",
    "            # Append to list of lane indices and apply frame of reference transformation\n",
    "            right_lane_idx.append(right_lane_idx_local + [win_y2,win_x1r])            \n",
    "    \n",
    "    # Concatenate all lane points to respective lane variables\n",
    "    left_lane_idx = np.concatenate(left_lane_idx[:], axis=0)\n",
    "    right_lane_idx = np.concatenate(right_lane_idx[:], axis=0)\n",
    "\n",
    "    \n",
    "    return left_lane_idx, right_lane_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Draw Lane Points on new image\n",
    "def draw_lane_points(img, left_lane_idx, right_lane_idx):\n",
    "    \n",
    "    new_img = np.zeros_like(img)\n",
    "    for i in range(len(left_lane_idx)):\n",
    "        for j in range(len(left_lane_idx[i])):\n",
    "            cv2.circle(new_img, (left_lane_idx[i][1],left_lane_idx[i][0]), 1, (255, 255, 0), 1)\n",
    "\n",
    "    for i in range(len(right_lane_idx)):\n",
    "        cv2.circle(new_img, (right_lane_idx[i][1],right_lane_idx[i][0]), 1, (255, 0, 0), 1)\n",
    "    \n",
    "    return new_img\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Fit lane lines\n",
    "\n",
    "def identify_lane(left_lane_idx, right_lane_idx, img_size):\n",
    "    \n",
    "    global prev_right_fit, right_fit_count\n",
    "    \n",
    "    # Obtain individual set of coordinates for each detected lane    \n",
    "    left_lane_y = np.array([item[0] for item in left_lane_idx])\n",
    "    left_lane_x = np.array([item[1] for item in left_lane_idx])\n",
    "    right_lane_y = np.array([item[0] for item in right_lane_idx])\n",
    "    right_lane_x = np.array([item[1] for item in right_lane_idx])\n",
    "\n",
    "    # Fit a second order polynomial to lane lines\n",
    "    left_fit = np.polyfit(left_lane_y , left_lane_x, 2)\n",
    "    left_fit_x = left_fit[0]*left_lane_y **2 + left_fit[1]*left_lane_y  + left_fit[2]\n",
    "    \n",
    "    right_fit = np.polyfit(right_lane_y, right_lane_x, 2)\n",
    "    right_fit_x = right_fit[0]*right_lane_y**2 + right_fit[1]*right_lane_y + right_fit[2]    \n",
    "\n",
    "    \n",
    "    # Extrapolation of left lane\n",
    "    top_left_y = top_right_y = 0\n",
    "    bottom_left_y = bottom_right_y = img_size[1]\n",
    "    \n",
    "    top_left_x = left_fit[0]*top_left_y**2 + left_fit[1]*top_left_y  + left_fit[2]\n",
    "    bottom_left_x = left_fit[0]*bottom_left_y**2 + left_fit[1]*bottom_left_y  + left_fit[2]\n",
    "    \n",
    "    left_fit_x = np.append(np.flipud(left_fit_x), top_left_x)\n",
    "    left_lane_y = np.append(np.flipud(left_lane_y), top_left_y)\n",
    "    \n",
    "    left_fit_x = np.append(np.flipud(left_fit_x), bottom_left_x)\n",
    "    left_lane_y = np.append(np.flipud(left_lane_y), bottom_left_y)\n",
    "        \n",
    "    \n",
    "    # Use previous frames to keep track of right lane\n",
    "    if len(right_lane_x)<1000 and right_fit_count==20:\n",
    "        right_fit = prev_right_fit/20\n",
    "        right_fit_count = 0\n",
    "        \n",
    "    elif right_fit_count == 0:\n",
    "        prev_right_fit = right_fit\n",
    "        \n",
    "    elif 0 < right_fit_count < 20:\n",
    "        right_fit_count += 1\n",
    "        prev_right_fit += right_fit\n",
    "    \n",
    "    # Extrapolation of right lane\n",
    "    top_right_x = right_fit[0]*top_right_y**2 + right_fit[1]*top_right_y + right_fit[2]\n",
    "    bottom_right_x = right_fit[0]*bottom_right_y**2 + right_fit[1]*bottom_right_y + right_fit[2]\n",
    "    \n",
    "    right_fit_x = np.append(np.flipud(right_fit_x), top_right_x)\n",
    "    right_lane_y = np.append(np.flipud(right_lane_y), top_right_y)\n",
    "\n",
    "    right_lane_y = np.append(np.flipud(right_lane_y), bottom_right_y)\n",
    "    right_fit_x = np.append(np.flipud(right_fit_x), bottom_right_x)\n",
    "    \n",
    "    return left_lane_y, right_lane_y, left_fit_x, right_fit_x, left_fit, right_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Draw curved lines on image\n",
    "def draw_curved_line(img, line_fit):\n",
    "    p = np.poly1d(line_fit)\n",
    "    x = list(range(0, img.shape[0]))\n",
    "    y = list(map(int, p(x)))\n",
    "    points = np.array([[y1,x1] for x1, y1 in zip(x, y)])\n",
    "    points = points.reshape((-1,1,2))\n",
    "    \n",
    "    cv2.polylines(img, np.int32([points]), False, color=(255,0,0), thickness=6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate lane curvature\n",
    "def lane_curvature(lane_fit_x, lane_fit_y):\n",
    "    \n",
    "    # Define conversions in x and y from pixels space to meters\n",
    "    ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "    xm_per_pix = 3.7/700 # meteres per pixel in x dimension\n",
    "\n",
    "    new_fit = np.polyfit(lane_fit_y*ym_per_pix, lane_fit_x*xm_per_pix, 2)\n",
    "    \n",
    "    y_eval = np.max(lane_fit_y)\n",
    "    \n",
    "    rad_curvature = ((1 + (2*new_fit[0]*y_eval + new_fit[1])**2)**1.5)/np.absolute(2*new_fit[0])\n",
    "        \n",
    "    return rad_curvature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate offset from lane center\n",
    "def distance_from_lane(img, left_lane, right_lane):\n",
    "    \n",
    "    xm_per_pix = 3.7/700 # meteres per pixel in x dimension\n",
    "    \n",
    "    img_center = (img.shape[1]//2, img.shape[0])\n",
    "    \n",
    "    car_pos = ((left_lane[-1] + right_lane[-1])//2 - img_center[0]) * xm_per_pix\n",
    "    \n",
    "    return car_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot lane over original image\n",
    "\n",
    "def draw_lane_line(image, left_lane_y, right_lane_y, left_fit_x, right_fit_x, M_inv):\n",
    "    \n",
    "    global frame_count\n",
    "    frame_count += 1\n",
    "\n",
    "    # Concatenate lane points\n",
    "    combined_lane_left = np.array([np.flipud((np.transpose(np.vstack((left_fit_x,left_lane_y)))))])\n",
    "    combined_lane_right = np.array([np.transpose(np.vstack((right_fit_x,right_lane_y)))])\n",
    "    combined_lane_idx = np.hstack((combined_lane_left,combined_lane_right))\n",
    "    \n",
    "    # Draw lane lines and fill lane area\n",
    "    img_draw = np.zeros_like(image)\n",
    "    cv2.polylines(img_draw, np.int_([combined_lane_idx]), isClosed=False, color=(0,0,255), thickness = 30)\n",
    "    cv2.fillPoly(img_draw, np.int_([combined_lane_idx]), (0,255, 0))\n",
    "    \n",
    "    # Unwarp transformed image\n",
    "    new_warp = cv2.warpPerspective(img_draw, M_inv, (image.shape[1], image.shape[0]))\n",
    "    new_img = cv2.addWeighted(image, 1, new_warp, 0.5, 0)\n",
    "    \n",
    "    # Get Radius of Curvature\n",
    "    left_lane_rad = lane_curvature(left_fit_x, left_lane_y)\n",
    "    right_lane_rad = lane_curvature(right_fit_x, right_lane_y)\n",
    "    \n",
    "    # Overlay Radius of Curvature (text)    \n",
    "    cv2.putText(new_img, \"Left Lane Radius: \" + str(\"%.2f\" % left_lane_rad) + \" (m)\", (100, 100), \n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255,255,255))\n",
    "    cv2.putText(new_img, \"Right Lane Radius: \" + str(\"%.2f\" % right_lane_rad) + \" (m)\", (100, 130), \n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255,255,255))\n",
    "    \n",
    "    # Get car position\n",
    "    vehicle_pos = distance_from_lane(new_img, left_fit_x, right_fit_x)\n",
    "    \n",
    "    # Overlay car position (text)\n",
    "    cv2.putText(new_img, \"Distance from car to road center: \" + str(\"%.2f\" % vehicle_pos) + \" (m)\", (100, 160), \n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255,255,255))\n",
    "    \n",
    "    return new_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Video pipeline\n",
    "def process_video(image):\n",
    "    \n",
    "    # Threshold Image\n",
    "    thresholded_image, M_inv = thresholded_img(image)\n",
    "    img_size = [image.shape[1], image.shape[0]]\n",
    "    \n",
    "    # Obtain lane coordinates\n",
    "    left_lane_idx, right_lane_idx = lane_coords(thresholded_image)\n",
    "    \n",
    "    # Identify Lane Lines\n",
    "    left_lane_y, right_lane_y, left_fit_x, right_fit_x, left_fit, right_fit = identify_lane(left_lane_idx, \n",
    "                                                                                            right_lane_idx, img_size)\n",
    "    \n",
    "    # Draw lane lines\n",
    "    final_img = draw_lane_line(image, left_lane_y, right_lane_y, left_fit_x, right_fit_x, M_inv)\n",
    "\n",
    "    \n",
    "    return final_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video project_output.mp4\n",
      "[MoviePy] Writing video project_output.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 1260/1261 [04:34<00:00,  4.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: project_output.mp4 \n",
      "\n",
      "CPU times: user 9min 48s, sys: 11.3 s, total: 10min\n",
      "Wall time: 4min 34s\n"
     ]
    }
   ],
   "source": [
    "### Prrocess video\n",
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "\n",
    "right_fit_count = 0\n",
    "frame_count = 0\n",
    "\n",
    "output = 'project_output.mp4'\n",
    "clip1 = VideoFileClip(\"project_video.mp4\")\n",
    "clip = clip1.fl_image(process_video) #NOTE: this function expects color images!!\n",
    "%time clip.write_videofile(output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Slider for interactive manual tuning for thresholding parameters\n",
    "'''\n",
    "try:\n",
    "    # Undistort test image\n",
    "    image = cv2.imread(images[5])\n",
    "    undist_image = cv2.undistort(image, camera_mtx, camera_dist, None, camera_mtx)\n",
    "    blurred_warped = cv2.GaussianBlur(warped,(5,5),0)\n",
    "\n",
    "    def color_thresh_test(img, colorspace = cv2.COLOR_BGR2HLS, threshold_min = 140, channel = 0):\n",
    "\n",
    "        img_convert = cv2.cvtColor(img, colorspace)\n",
    "        img_ch = img_convert[:,:,channel]\n",
    "        #gray_warped = cv2.cvtColor(img_ch, cv2.COLOR_RGB2GRAY)\n",
    "        #binary_img = combined_binary_threshold(img_ch, sobel_kernel=7, abs_thresh=(threshold_min, 255), \n",
    "                                                            #mag_thresh=(threshold_min, 255), dir_thresh=(0.1, 0.9))\n",
    "        \n",
    "        thresh = (threshold_min, 255)\n",
    "        \n",
    "        \n",
    "        binary_img = np.zeros_like(img_ch)\n",
    "        ret, binary_img = cv2.threshold(img_ch, thresh[0], thresh[1], cv2.THRESH_BINARY)\n",
    "        #binary_img[((img_ch > thresh[0]) & (img_ch <= thresh[1]))] = 255\n",
    "        \n",
    "        return binary_img\n",
    "\n",
    "    cv2.namedWindow('image')\n",
    "\n",
    "    def nothing(x):\n",
    "        pass\n",
    "\n",
    "    # Create slider/trackbar for threshold min/max\n",
    "    cv2.createTrackbar('Threshold','image',0,255,nothing)\n",
    "\n",
    "\n",
    "    # Allocate destination image\n",
    "    threshold_image = np.zeros_like(warped)\n",
    "    while(1):\n",
    "\n",
    "        k = cv2.waitKey(1) & 0xFF\n",
    "        if k == 27:\n",
    "            break\n",
    "\n",
    "        # Get threshold value\n",
    "        threshold_val = cv2.getTrackbarPos('Threshold','image')\n",
    "\n",
    "        threshold_image = color_thresh_test(warped, colorspace = cv2.COLOR_BGR2HLS, threshold_min = threshold_val, channel = 2)\n",
    "        cv2.imshow('image', threshold_image)\n",
    "    cv2.destroyAllWindows()\n",
    "except:\n",
    "    print(\"error\")\n",
    "    cv2.destroyAllWindows()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
